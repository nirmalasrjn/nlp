{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "561178bd-cfb1-4195-9443-3bca1462b3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./lib/python3.9/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in ./lib/python3.9/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./lib/python3.9/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./lib/python3.9/site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in ./lib/python3.9/site-packages (from nltk) (4.66.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc07536f-76ce-406b-86ea-1c4c73fda81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7546481b-cfbd-45ba-b455-6dfb95209dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content of the file\n",
    "with open('Nyt.200811.txt', 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "033fcc33-da4d-49fb-b276-2ea7c4365827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized words:\n",
      "['KBR', 'said', 'Friday', 'the', 'global', 'economic', 'downturn', 'so', 'far', 'has', 'had', 'little', 'effect', 'on', 'its', 'business', 'but', 'warned', 'some', 'projects']\n",
      "Total number of tokens: 597333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text into words\n",
    "tokens = word_tokenize(text)\n",
    "print(f\"Tokenized words:\")\n",
    "print(tokens[:20])\n",
    "print(f\"Total number of tokens: {len(tokens)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9d36ef1-098b-453e-975e-30f307a586bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few twenty tokens in token1:\n",
      "['KBR', 'said', 'Friday', 'the', 'global', 'economic', 'downturn', 'so', 'far', 'has', 'had', 'little', 'effect', 'on', 'its', 'business', 'but', 'warned', 'some', 'projects']\n",
      "First few twenty tokens in token2:\n",
      "['said', 'Friday', 'the', 'global', 'economic', 'downturn', 'so', 'far', 'has', 'had', 'little', 'effect', 'on', 'its', 'business', 'but', 'warned', 'some', 'projects', 'on']\n",
      "Total number of tokens in token1: 597332\n",
      "\n",
      "Total number of tokens in token2: 597332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create almost two duplicate list of records off by one line \n",
    "tokens1 = tokens[:-1] # All tokens except the last one\n",
    "tokens2 = tokens[1:] # All tokens except the first one \n",
    "\n",
    "print(f\"First few twenty tokens in token1:\")\n",
    "print(tokens1[:20])\n",
    "print(f\"First few twenty tokens in token2:\")\n",
    "print(tokens2[:20])\n",
    "\n",
    "print(f\"Total number of tokens in token1: {len(tokens1)}\\n\")\n",
    "print(f\"Total number of tokens in token2: {len(tokens2)}\\n\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9963f3fb-71bd-4265-a264-20257d5d1146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First ten bigrams:\n",
      "[('KBR', 'said'), ('said', 'Friday'), ('Friday', 'the'), ('the', 'global'), ('global', 'economic'), ('economic', 'downturn'), ('downturn', 'so'), ('so', 'far'), ('far', 'has'), ('has', 'had')]\n",
      "Total number of bigrams: 597332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate bigrams\n",
    "bigrams = list(zip(tokens1, tokens2))\n",
    "print(f\"First ten bigrams:\")\n",
    "print(bigrams[:10])\n",
    "print(f\"Total number of bigrams: {len(bigrams)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf28fc9-d73d-435a-b15d-cdbc54947134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each bigram\n",
    "bigram_freq = Counter(bigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8c1bb1-adfa-441e-acaf-94ca6cd97652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 most common bigrams\n",
    "most_common_bigrams = bigram_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13906ed6-9152-48a7-bf54-053de808f95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.', '``'): 3651\n",
      "('of', 'the'): 3091\n",
      "(',', \"''\"): 2794\n",
      "('in', 'the'): 2501\n",
      "('.', \"''\"): 2407\n",
      "('.', 'The'): 2193\n",
      "(',', 'the'): 2092\n",
      "(',', 'and'): 1924\n",
      "(',', 'a'): 1303\n",
      "('to', 'the'): 1172\n"
     ]
    }
   ],
   "source": [
    "# Print the 10 most common bigrams\n",
    "for bigram, freq in most_common_bigrams:\n",
    "    print(f'{bigram}: {freq}')                           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
